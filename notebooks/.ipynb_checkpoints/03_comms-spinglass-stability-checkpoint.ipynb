{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:16.624565Z",
     "start_time": "2021-09-06T16:43:14.745999Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:16.630174Z",
     "start_time": "2021-09-06T16:43:16.626036Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "av_corrs_rho = pd.read_pickle(open('../data/av_corrs_rho_by_group_density0_07.pck','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:16.633527Z",
     "start_time": "2021-09-06T16:43:16.631831Z"
    }
   },
   "outputs": [],
   "source": [
    "density = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:17.343128Z",
     "start_time": "2021-09-06T16:43:16.635210Z"
    }
   },
   "outputs": [],
   "source": [
    "def density_threshold(mat, density, binarized=False):\n",
    "    ind = np.triu_indices_from(mat)\n",
    "    values = mat[ind]\n",
    "    thr_value = np.quantile(values, 1.0-density)\n",
    "    thr_mat = mat.copy()\n",
    "    thr_mat[mat < thr_value] = 0\n",
    "    if binarized == True:\n",
    "        thr_mat[mat >= thr_value] = 1  # binarization\n",
    "    return thr_mat\n",
    "\n",
    "\n",
    "def correlation_threshold(mat, thr_corr, binarized=False):\n",
    "    ind = np.triu_indices_from(mat)\n",
    "    values = mat[ind]\n",
    "    thr_mat = mat.copy()\n",
    "    thr_mat[mat < thr_corr] = 0\n",
    "    if binarized == True:\n",
    "        thr_mat[mat >= thr_corr] = 1  # binarization\n",
    "    return thr_mat\n",
    "\n",
    "\n",
    "correlation_thr = 0.1\n",
    "effective_viz_matrices = {}\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "for k, i in enumerate(av_corrs_rho.keys()):\n",
    "    plt.subplot(2, 4, k+1)\n",
    "    plt.imshow(av_corrs_rho[i] - np.eye(70))\n",
    "    print(nx.density(nx.from_pandas_adjacency(av_corrs_rho[i])))\n",
    "    effective_viz_matrices[i] = pd.DataFrame(correlation_threshold(\n",
    "        av_corrs_rho[i].values, correlation_thr), columns=av_corrs_rho[i].columns, index=av_corrs_rho[i].index)\n",
    "    print(nx.density(nx.from_pandas_adjacency(effective_viz_matrices[i])))\n",
    "    plt.subplot(2, 4, k+5)\n",
    "    plt.imshow(effective_viz_matrices[i] - np.eye(70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:17.346641Z",
     "start_time": "2021-09-06T16:43:17.344497Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:18.122019Z",
     "start_time": "2021-09-06T16:43:17.347764Z"
    }
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "add_isolated = True\n",
    "IG_comms = {}\n",
    "ig_final = {}\n",
    "\n",
    "\n",
    "partition_iterations = 100;\n",
    "\n",
    "for i in tqdm(av_corrs_rho):\n",
    "    IG_comms[i] = {}\n",
    "    G = nx.from_pandas_adjacency(av_corrs_rho[i], create_using=nx.Graph())\n",
    "    ## detect only on giant component\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    nx.write_graphml(G, '../data/test-ig.graphml')\n",
    "    g = ig.load('../data/test-ig.graphml')\n",
    "    GC = nx.subgraph(G, max(nx.connected_components(G), key=len))\n",
    "    ## keep track of isolated nodes\n",
    "    isolated_nodes = set(list(G.nodes())) - set(list(GC.nodes()));\n",
    "    ## setup (awkwardly) the comm detection\n",
    "    nx.write_graphml(GC, '../data/test-ig-gc.graphml')\n",
    "    gc = ig.load('../data/test-ig-gc.graphml')\n",
    "    for it in range(partition_iterations):\n",
    "        IG_comms[i][it] = gc.community_leiden('modularity', weights='weight', n_iterations = 2)\n",
    "#         print(len(set(IG_comms[i][it].membership)))\n",
    "        IG_comms[i][it] = dict(zip(gc.vs['id'], IG_comms[i][it].membership))\n",
    "        if add_isolated==True:\n",
    "            max_comm = np.max(list(IG_comms[i][it].values()))\n",
    "            for n in isolated_nodes:\n",
    "                max_comm += 1;\n",
    "                IG_comms[i][it][n] = max_comm;\n",
    "    print(i, [len(set(IG_comms[i][x].values())) for x in range(partition_iterations)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:18.126523Z",
     "start_time": "2021-09-06T16:43:18.123769Z"
    }
   },
   "outputs": [],
   "source": [
    "relabel_parts = dict(zip(list(G.nodes()), range(len(list(G.nodes())))))\n",
    "inv_relabel_parts = dict(zip(range(len(list(G.nodes()))), list(G.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:18.133659Z",
     "start_time": "2021-09-06T16:43:18.129910Z"
    }
   },
   "outputs": [],
   "source": [
    "def comm_to_nodes(cludict, relabel = None):\n",
    "    from collections import defaultdict\n",
    "    ctn_dict = defaultdict(list)\n",
    "    if relabel == None:\n",
    "        for n in cludict:\n",
    "            ctn_dict[cludict[n]].append(n)\n",
    "    else:\n",
    "        for n in cludict:\n",
    "            ctn_dict[cludict[n]].append(relabel[n])\n",
    "    return ctn_dict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:18.142513Z",
     "start_time": "2021-09-06T16:43:18.135638Z"
    }
   },
   "outputs": [],
   "source": [
    "ctn = {}\n",
    "for i in IG_comms:\n",
    "    ctn[i] = {}\n",
    "    for it in IG_comms[i]:\n",
    "        ctn[i][it] = comm_to_nodes(IG_comms[i][it], relabel_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:19.658894Z",
     "start_time": "2021-09-06T16:43:18.143821Z"
    }
   },
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "\n",
    "IG_comms_center = {}\n",
    "for i in tqdm(ctn):\n",
    "    parts = [list(IG_comms[i][x].values()) for x in IG_comms[i]]\n",
    "    IG_comms_center[i] = gt.partition_overlap_center(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:19.666199Z",
     "start_time": "2021-09-06T16:43:19.660820Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in IG_comms:\n",
    "    print('Best partition for ', i , 'Num comms:', len(set(IG_comms_center[i][0])), 'Nodes covered: ',\n",
    "          len(IG_comms_center[i][0]), ' \\n', IG_comms_center[i][0])\n",
    "    print('Confidence ', IG_comms_center[i][1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:19.706189Z",
     "start_time": "2021-09-06T16:43:19.667704Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in IG_comms_center:\n",
    "    relabel = dict(zip(G.nodes(), IG_comms_center[i][0]))\n",
    "    ig_final[i] = nx.from_pandas_adjacency(effective_viz_matrices[i], create_using=nx.Graph())\n",
    "    ig_final[i].remove_edges_from(nx.selfloop_edges(ig_final[i]))\n",
    "    nx.set_node_attributes(ig_final[i], relabel, 'spin_comms')\n",
    "    if i==('U', 'A'):\n",
    "        regular_comm = relabel.copy();\n",
    "    \n",
    "for i in ig_final:\n",
    "    nx.set_node_attributes(ig_final[i], regular_comm, 'control_spin_comms')\n",
    "    nx.write_gexf(ig_final[i], '../data/viz-data/finalized_spinglass_comms_graphs_'+str(i).replace(\"'\", \"_\")+'.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:19.709975Z",
     "start_time": "2021-09-06T16:43:19.707603Z"
    }
   },
   "outputs": [],
   "source": [
    "center_ctn = {}\n",
    "for i in IG_comms_center:\n",
    "    dic = dict(zip(list(G.nodes()), IG_comms_center[i][0]))\n",
    "    center_ctn[i] = comm_to_nodes(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:19.767679Z",
     "start_time": "2021-09-06T16:43:19.712115Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "def intra_edges_weight(gg, comm_nodes, measure = 'weighted'):\n",
    "    reduced_g = nx.subgraph(gg, comm_nodes);\n",
    "    w = nx.get_edge_attributes(reduced_g, 'weight');\n",
    "    if measure == 'weighted':\n",
    "        return np.sum(list(w.values()));\n",
    "    else:\n",
    "        return(2 * len(w) / (len(comm_nodes)**2) );\n",
    "\n",
    "def inter_edges_weight(gg, comm1, comm2, measure='weighted'):\n",
    "    s = 0\n",
    "    for n in comm1:\n",
    "        for m in comm2:\n",
    "            if gg.has_edge(n,m):\n",
    "                if measure =='weighted':\n",
    "                    s += gg[n][m]['weight'];\n",
    "                else:\n",
    "                    s += 1;\n",
    "    if measure == 'weighted':\n",
    "        return s;\n",
    "    else:\n",
    "        return s / (len(comm1) * len(comm2));\n",
    "\n",
    "comm_structure = {}\n",
    "for i in av_corrs_rho:\n",
    "    print(i);\n",
    "    deh = []\n",
    "    G = nx.from_pandas_adjacency(av_corrs_rho[i], create_using=nx.Graph())\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    comm_structure[i] = np.zeros((len(center_ctn[i]), len(center_ctn[i])));\n",
    "    for j, comm in enumerate(center_ctn[i].values()):\n",
    "        comm_structure[i][j,j] = intra_edges_weight(G, comm)\n",
    "    for j, jj in combinations(sorted(center_ctn[i].keys()), 2):\n",
    "        comm_structure[i][j,jj] = inter_edges_weight(G, center_ctn[i][j], center_ctn[i][jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:20.399264Z",
     "start_time": "2021-09-06T16:43:19.769669Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "count = 1\n",
    "for i in comm_structure:\n",
    "    plt.subplot(2, 2, count)\n",
    "    sns.heatmap(comm_structure[i])\n",
    "    count += 1\n",
    "    plt.title(i)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:21.268594Z",
     "start_time": "2021-09-06T16:43:20.401340Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 4))\n",
    "count = 1\n",
    "\n",
    "\n",
    "names = [('U', 'A'), ('U', 'S'), ('P', 'A'), ('P', 'S')]\n",
    "cmap = None\n",
    "for i in names:\n",
    "    plt.subplot(1, 4, count)\n",
    "    if i == ('U', 'S'):\n",
    "        sns.heatmap(comm_structure[i][:5, :5], cmap=cmap, vmin=0, alpha=1)\n",
    "    else:\n",
    "        sns.heatmap(comm_structure[i], cmap=cmap,  vmin=0, alpha=1)\n",
    "    count += 1\n",
    "    plt.title(i, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/comm_structure_plots.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T16:32:06.449961Z",
     "start_time": "2021-09-05T16:32:06.447683Z"
    }
   },
   "source": [
    "# Compute r values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:43:21.274910Z",
     "start_time": "2021-09-06T16:43:21.270601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in comm_structure:\n",
    "    di = np.diag_indices_from(comm_structure[i])\n",
    "    ind = np.triu_indices_from(comm_structure[i], 1)\n",
    "    print(i, np.mean(comm_structure[i][di][comm_structure[i][di]>0]) / np.mean(comm_structure[i][ind][comm_structure[i][ind]>0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:38.335506Z",
     "start_time": "2021-09-06T16:43:21.276381Z"
    }
   },
   "outputs": [],
   "source": [
    "# random model for the r ratios\n",
    "def compute_random_comm_structure(data, cond, comms):\n",
    "    G = nx.from_pandas_adjacency(data[cond], create_using=nx.Graph())\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    random_comm_structure = np.zeros((len(comms[cond]), len(comms[cond])))\n",
    "    nodes = list(G.nodes())\n",
    "    for j, comm in enumerate(comms[cond].values()):\n",
    "        rcomm = np.random.choice(nodes, size=len(comm), replace=False)\n",
    "        random_comm_structure[j, j] = intra_edges_weight(G, rcomm)\n",
    "    for j, jj in combinations(sorted(comms[cond].keys()), 2):\n",
    "        rcomm1 = np.random.choice(nodes, size=len(comms[cond][j]), replace=False)\n",
    "        rcomm2 = np.random.choice(nodes, size=len(comms[cond][jj]), replace=False)\n",
    "        random_comm_structure[j, jj] = inter_edges_weight(\n",
    "            G, rcomm1, rcomm2)\n",
    "    return random_comm_structure\n",
    "\n",
    "\n",
    "def r_ratio(cs):\n",
    "    di = np.diag_indices_from(cs)\n",
    "    ind = np.triu_indices_from(cs, 1)\n",
    "    return np.mean(cs[di][cs[di] > 0]) / np.mean(cs[ind][cs[ind] > 0])\n",
    "\n",
    "num_iter = 4000\n",
    "random_r_distribs = {}\n",
    "for i in tqdm(av_corrs_rho):\n",
    "    random_r_distribs[i] = [r_ratio(compute_random_comm_structure(\n",
    "        av_corrs_rho, i, center_ctn)) for it in range(num_iter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:39.244511Z",
     "start_time": "2021-09-06T16:46:38.337545Z"
    }
   },
   "outputs": [],
   "source": [
    "count=1 \n",
    "from scipy.stats import percentileofscore\n",
    "fig = plt.figure(figsize=(16,3))\n",
    "record = []\n",
    "for i in comm_structure:\n",
    "    r = r_ratio(comm_structure[i])\n",
    "    print(i, r, np.quantile(random_r_distribs[i], 0.95), percentileofscore(random_r_distribs[i], r)) \n",
    "    record.append([i, r, percentileofscore(random_r_distribs[i], r)/100])\n",
    "    plt.subplot(1,4,count)\n",
    "    plt.title(i)\n",
    "    plt.hist(random_r_distribs[i], np.linspace(0,2.5,400), density=True, stacked=True,\n",
    "             label='null', alpha=.5, histtype='step', linewidth=2)\n",
    "    count+=1\n",
    "    plt.vlines(r, 0, 4.5, color='orange', linestyle='dashed', label=r'$r$')\n",
    "    plt.xlim(0,2.6)\n",
    "    plt.ylim(0,6)\n",
    "    plt.legend(loc=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/r-significance-plots.pdf')\n",
    "\n",
    "df = pd.DataFrame(record, columns = ['cond', r'$r$', 'p-value'] )\n",
    "df.to_excel('../data/r-significance.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:39.255395Z",
     "start_time": "2021-09-06T16:46:39.245929Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T16:31:36.990296Z",
     "start_time": "2021-09-05T16:31:36.988016Z"
    }
   },
   "source": [
    "## Significance of differences between r values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:40.202213Z",
     "start_time": "2021-09-06T16:46:39.258557Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_sample = 10000;\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "count = 1\n",
    "record = []\n",
    "for i, ii in combinations(list(comm_structure.keys()), 2):\n",
    "    plt.subplot(2,3,count)\n",
    "    diffs = np.random.choice(random_r_distribs[i],diff_sample) - np.random.choice(random_r_distribs[ii],diff_sample)\n",
    "    real_diff =  r_ratio(comm_structure[i]) - r_ratio(comm_structure[ii]) \n",
    "    print(i, ii, real_diff, percentileofscore(diffs, real_diff)/100) \n",
    "    record.append([i, ii, real_diff, percentileofscore(diffs, real_diff)/100])\n",
    "    plt.title((i,ii))\n",
    "    plt.hist(diffs, np.linspace(-.4,.4,100), density=True, stacked=True,\n",
    "             label='null', alpha=.5, histtype='step', linewidth=2)\n",
    "    count+=1\n",
    "    plt.vlines(real_diff, 0, 4.5, color='orange', linestyle='dashed', label=r'$\\Delta r$')\n",
    "#     plt.xlim(0,1)\n",
    "    plt.ylim(0,6)\n",
    "    plt.legend(loc=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/delta-r-significance-plots.pdf')\n",
    "\n",
    "df = pd.DataFrame(record, columns = ['cond1', 'cond2', r'$r_1$ - $r_2$', 'p-value'] )\n",
    "df.to_excel('../data/delta-r-significance.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:40.217216Z",
     "start_time": "2021-09-06T16:46:40.205135Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T17:00:09.830043Z",
     "start_time": "2020-06-09T17:00:09.827379Z"
    }
   },
   "source": [
    "# community overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:40.228360Z",
     "start_time": "2021-09-06T16:46:40.218899Z"
    }
   },
   "outputs": [],
   "source": [
    "def comm_jaccard(a, b):\n",
    "    num = len(set(a).intersection(set(b)))\n",
    "    den = len(set(a).union(set(b)))\n",
    "    return num/den\n",
    "\n",
    "\n",
    "def partition_overlap(ctn1, ctn2):\n",
    "    conf = {}\n",
    "    for c in ctn1:\n",
    "        conf[c] = {}\n",
    "        for cc in ctn2:\n",
    "            conf[c][cc] = comm_jaccard(ctn1[c], ctn2[cc])\n",
    "    return pd.DataFrame(conf)\n",
    "\n",
    "\n",
    "def z_comm_jaccard(a, b, nodes, num_samples=1000, thr=None):\n",
    "    real_jacc = comm_jaccard(a,b)\n",
    "    samples = []\n",
    "    for n in range(num_samples):\n",
    "        x = np.random.choice(nodes, len(a), replace=False) \n",
    "        y = np.random.choice(nodes, len(b), replace=False)\n",
    "        samples.append(comm_jaccard(x, y));\n",
    "    if thr==None:\n",
    "        return (real_jacc - np.mean(samples)) / np.std(samples)\n",
    "    else:\n",
    "        if (real_jacc - np.mean(samples)) / np.std(samples)<-thr:\n",
    "            return (real_jacc - np.mean(samples)) / np.std(samples);\n",
    "        elif (real_jacc - np.mean(samples)) / np.std(samples)>thr:\n",
    "            return (real_jacc - np.mean(samples)) / np.std(samples)\n",
    "        else:\n",
    "            return 0;\n",
    "\n",
    "def z_partition_overlap(ctn1, ctn2, nodes, num_samples=1000, thr=None):\n",
    "    conf = {}\n",
    "    for c in ctn1:\n",
    "        conf[c] = {}\n",
    "        for cc in ctn2:\n",
    "            conf[c][cc] = z_comm_jaccard(ctn1[c], ctn2[cc], nodes, num_samples=num_samples, thr=thr)\n",
    "    return pd.DataFrame(conf)\n",
    "\n",
    "\n",
    "def alpha_comm_jaccard(a, b, nodes, num_samples=1000, alpha=0.05):\n",
    "    real_jacc = comm_jaccard(a,b)\n",
    "    samples = []\n",
    "    for n in range(num_samples):\n",
    "        x = np.random.choice(nodes, len(a), replace=False) \n",
    "        y = np.random.choice(nodes, len(b), replace=False)\n",
    "        samples.append(comm_jaccard(x, y));\n",
    "    if alpha==None:\n",
    "        return (real_jacc - np.mean(samples)) / np.std(samples)\n",
    "    else:\n",
    "        lower_quantile = np.quantile(samples, alpha);\n",
    "        upper_quantile = np.quantile(samples, 1 -  alpha)\n",
    "        if real_jacc<lower_quantile:\n",
    "            return real_jacc - np.mean(samples);\n",
    "        elif real_jacc > upper_quantile:\n",
    "            return real_jacc - np.mean(samples)\n",
    "        else:\n",
    "            return 0;\n",
    "\n",
    "def alpha_partition_overlap(ctn1, ctn2, nodes, num_samples=1000, alpha=0.05):\n",
    "    conf = {}\n",
    "    for c in ctn1:\n",
    "        conf[c] = {}\n",
    "        for cc in ctn2:\n",
    "            conf[c][cc] = alpha_comm_jaccard(ctn1[c], ctn2[cc], nodes, num_samples=num_samples, alpha=alpha)\n",
    "    return pd.DataFrame(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:46:41.322620Z",
     "start_time": "2021-09-06T16:46:40.229991Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "count = 1\n",
    "for i, ii in combinations(center_ctn.keys(), 2):\n",
    "    plt.subplot(2, 3, count)\n",
    "    df = partition_overlap(center_ctn[i], center_ctn[ii])\n",
    "    sns.heatmap(df, vmin=0, vmax=.5)\n",
    "    plt.title([i, ii, np.mean(np.mean(df))])\n",
    "    count += 1;\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:14.046585Z",
     "start_time": "2021-09-06T16:46:41.324089Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "count = 1\n",
    "zdf = {}\n",
    "for i, ii in combinations(center_ctn.keys(), 2):\n",
    "    plt.subplot(2, 3, count)\n",
    "    zdf[(i, ii)] = z_partition_overlap(center_ctn[i], center_ctn[ii],\n",
    "                                       range(G.number_of_nodes()), thr=3, num_samples=5000)\n",
    "    sns.heatmap(zdf[(i, ii)], cmap='BrBG')  # vmin=-3, vmax=3,\n",
    "    plt.title([i, ii, np.mean(np.mean(np.abs(zdf[(i, ii)]))),\n",
    "               np.mean(np.mean(zdf[(i, ii)]))])\n",
    "    count += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.250596Z",
     "start_time": "2021-09-06T16:47:14.048457Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "count = 1\n",
    "alpha_df = {}\n",
    "for i, ii in combinations(center_ctn.keys(), 2):\n",
    "    plt.subplot(2, 3, count)\n",
    "    alpha_df[(i, ii)] = alpha_partition_overlap(center_ctn[i], center_ctn[ii], range(G.number_of_nodes()),\n",
    "                                                num_samples=5000, alpha=0.01)\n",
    "    sns.heatmap(alpha_df[(i, ii)], cmap='BrBG')  # vmin=-3, vmax=3,\n",
    "    plt.title([i, ii, np.mean(np.mean(np.abs(alpha_df[(i, ii)]))),\n",
    "               np.mean(np.mean(alpha_df[(i, ii)]))])\n",
    "    count += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.255923Z",
     "start_time": "2021-09-06T16:47:46.252768Z"
    }
   },
   "outputs": [],
   "source": [
    "social_learning = [('P', 'A'), ('P', 'S')]\n",
    "pure_learning = [('P', 'A'), ('U', 'A')]\n",
    "pure_sociality = [('U', 'A'), ('U', 'S')]\n",
    "complete_task  = [('P', 'S'), ('U', 'S')]\n",
    "maximum_weird = [('P', 'S'), ('U', 'A')]\n",
    "even_weirder = [('P', 'A'), ('U', 'S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.260153Z",
     "start_time": "2021-09-06T16:47:46.257931Z"
    }
   },
   "outputs": [],
   "source": [
    "only_visual_stimulus = [('U', 'A'), ('U', 'S')]\n",
    "consimilar_recon = [('P', 'S'), ('U', 'S')]\n",
    "learned_response = [('P', 'A'), ('P', 'S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.263210Z",
     "start_time": "2021-09-06T16:47:46.261476Z"
    }
   },
   "outputs": [],
   "source": [
    "def common_nodes(a, b): \n",
    "    return set(a).intersection(set(b));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.270386Z",
     "start_time": "2021-09-06T16:47:46.264380Z"
    }
   },
   "outputs": [],
   "source": [
    "common_nodes_dict = {}\n",
    "for cond in [social_learning, pure_learning, pure_sociality, maximum_weird, complete_task, even_weirder]:\n",
    "    test = zdf[tuple(cond)]\n",
    "    arr  = np.array(test)\n",
    "    a, b = np.where(arr == numpy.amax(arr))\n",
    "    print(cond, zdf[tuple(cond)][b[0]][a[0]], comm_jaccard(ctn[cond[0]][b[0]], ctn[cond[1]][a[0]]))\n",
    "    common_nodes_dict[tuple(cond)] = [i for i in common_nodes(ctn[cond[0]][b[0]], ctn[cond[1]][a[0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.277670Z",
     "start_time": "2021-09-06T16:47:46.271622Z"
    }
   },
   "outputs": [],
   "source": [
    "chosen_sigma = 3\n",
    "\n",
    "common_nodes_dict = {}\n",
    "for cond in [social_learning, pure_learning, pure_sociality, maximum_weird, complete_task, even_weirder]:\n",
    "    print(cond)\n",
    "    test = zdf[tuple(cond)]\n",
    "    J, I = test.shape;\n",
    "    common_nodes_dict[tuple(cond)] = []\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if test[i][j]>chosen_sigma:\n",
    "                print(zdf[tuple(cond)][i][j], comm_jaccard(center_ctn[cond[0]][i], center_ctn[cond[1]][j]))\n",
    "                common_nodes_dict[tuple(cond)].append([i for i in common_nodes(center_ctn[cond[0]][i], center_ctn[cond[1]][j])])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.281572Z",
     "start_time": "2021-09-06T16:47:46.279125Z"
    }
   },
   "outputs": [],
   "source": [
    "for deh in common_nodes_dict:\n",
    "    print(deh)\n",
    "    for nodes in common_nodes_dict[deh]:\n",
    "        print(len(nodes), nodes)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T16:47:46.285030Z",
     "start_time": "2021-09-06T16:47:46.282809Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_names= {}\n",
    "comparison_names[('U', 'A'), ('U', 'S')] = 'visual_stimulus'\n",
    "comparison_names[('P', 'S'), ('U', 'S')]  = 'consimilar_recognition'\n",
    "comparison_names[('P', 'A'), ('P', 'S')] = 'learned_response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T12:46:37.862332Z",
     "start_time": "2021-09-08T12:46:37.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "module_viz_graph = nx.Graph()\n",
    "module_viz_graph.add_nodes_from(G.nodes())\n",
    "for deh in common_nodes_dict:\n",
    "    if deh in comparison_names:\n",
    "        labels = dict.fromkeys(list(G.nodes()), '')\n",
    "        if deh == 'visual_stimulus':\n",
    "            comm_part = dict.fromkeys(module_viz_graph.nodes(), 0)\n",
    "            for num_comm, comm_nodes in enumerate(common_nodes_dict[deh]):\n",
    "                for node in comm_nodes:\n",
    "                    comm_part[node] = num_comm + 1;\n",
    "                    labels[node] = node\n",
    "            nx.set_node_attributes(module_viz_graph, comm_part, comparison_names[deh])\n",
    "            nx.set_node_attributes(module_viz_graph, labels, comparison_names[deh]+ 'labels')\n",
    "            \n",
    "        else:\n",
    "            comm_part = dict.fromkeys(module_viz_graph.nodes(), 0)\n",
    "            for num_comm, comm_nodes in enumerate(common_nodes_dict[deh]):\n",
    "                for node in comm_nodes:\n",
    "                    if node in common_nodes_dict[('U', 'A'), ('U', 'S')][0]:\n",
    "                        comm_part[node] = 1;\n",
    "                    if node in common_nodes_dict[('U', 'A'), ('U', 'S')][1]:\n",
    "                        comm_part[node] = 2;\n",
    "                        labels[node] = node\n",
    "                    if comm_part[node] == 0:\n",
    "                        comm_part[node] = num_comm + 3\n",
    "                    labels[node] = node\n",
    "                        \n",
    "            nx.set_node_attributes(module_viz_graph, comm_part, comparison_names[deh])\n",
    "            nx.set_node_attributes(module_viz_graph, labels, comparison_names[deh]+ 'labels')\n",
    "\n",
    "nx.set_node_attributes(module_viz_graph, regular_comm, 'control_spin_comms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T12:46:38.515000Z",
     "start_time": "2021-09-08T12:46:38.510844Z"
    }
   },
   "outputs": [],
   "source": [
    "common_nodes_dict[('U', 'A'), ('U', 'S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T12:46:38.660092Z",
     "start_time": "2021-09-08T12:46:38.658067Z"
    }
   },
   "outputs": [],
   "source": [
    "ordered_keys = list(comparison_names.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T12:46:38.983849Z",
     "start_time": "2021-09-08T12:46:38.977074Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(module_viz_graph, '../data/viz-data/module_viz_graph.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenv",
   "language": "python",
   "name": "stenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
