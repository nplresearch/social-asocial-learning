{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of correlation networks using all correlations removing the mean-corr matrix plus weighted correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_data = pd.read_hdf('../data/proper_data.hdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we group the the data by condition and treatment, in order to be able to compute correlations only on the \n",
    "# appropriate values\n",
    "groups = proper_data.groupby(['Condition', 'Treatment'])\n",
    "regions = proper_data.columns[2:]\n",
    "num_regions = len(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of correlation matrices \n",
    "Here we compute the correlation matrices the difference between the various notebooks will be mostly in here, as we are exploring slightly different ways to \n",
    "compute these correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = {}\n",
    "sig_thr = 1; #here we choose the significance threshold for the correlations to be kept\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sample_sizes = [3,4,5,6,7,8]\n",
    "for sample_size in tqdm(sample_sizes): #resampling step\n",
    "    corrs[sample_size] = {}\n",
    "    for i, group in groups:\n",
    "        corrs[sample_size][i] = {}\n",
    "        for indices in combinations(range(group.shape[0]), sample_size):\n",
    "            mat = np.zeros((70,70));\n",
    "            for l, r in enumerate(regions):\n",
    "                for m, rr in enumerate(regions):\n",
    "                    c, p = pearsonr(np.array(group[r])[list(indices)],np.array(group[rr])[list(indices)]);\n",
    "                    if p<sig_thr:\n",
    "                        mat[l,m] = c;\n",
    "            corrs[sample_size][i][indices] = pd.DataFrame(mat, columns=regions, index=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pk.dump(corrs, open('../data/resampled_corrs.pck','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensor_graph(graph_tower):\n",
    "    # reshaping \n",
    "    L = len(graph_tower)\n",
    "    x = graph_tower[list(graph_tower.keys())[0]].shape[0]\n",
    "    keys = list(graph_tower.keys())\n",
    "    mat = np.zeros((L, x, x))\n",
    "    for l in range(L):\n",
    "        mat[l, :, :] = graph_tower[keys[l]];\n",
    "    return mat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_maths = {}\n",
    "for i, group in groups:\n",
    "    dist_maths[i] = np.zeros((len(sample_sizes), len(sample_sizes)));\n",
    "    for j, sz in enumerate(sample_sizes):\n",
    "        ind = np.triu_indices(70,1)\n",
    "        for jj, sszz in enumerate(sample_sizes):\n",
    "            x, y = np.mean(extract_tensor_graph(corrs[sz][i]), 0), np.mean(extract_tensor_graph(corrs[sszz][i]), 0)\n",
    "            r, p = pearsonr(x[ind], y[ind]);\n",
    "            dist_maths[i][j,jj] = r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j = 1;\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for i, group in groups:\n",
    "    plt.subplot(1,4,j)\n",
    "    plt.imshow(dist_maths[i])\n",
    "    plt.colorbar()\n",
    "    j+=1;\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependence on density of the correlation between resamplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_threshold(mat, density, binarized=False):\n",
    "    ind = np.triu_indices_from(mat);\n",
    "    values = mat[ind]\n",
    "    thr_value = np.quantile(values,1.0-density);\n",
    "    thr_mat = mat.copy();\n",
    "    thr_mat[mat<thr_value] = 0;\n",
    "    if binarized==True:\n",
    "        thr_mat[mat>=thr_value] = 1; #binarization\n",
    "    return thr_mat;\n",
    "\n",
    "\n",
    "rhos = np.linspace(0.001, .1, 20)\n",
    "# rhos = np.logspace(-3,-0.5,10)\n",
    "sz = 4;\n",
    "dist_maths_rho = {}\n",
    "corrs_rho = {}\n",
    "for rho in rhos:\n",
    "    corrs_rho[rho] = {}\n",
    "    for i, group in groups:\n",
    "        corrs_rho[rho][i] = {}\n",
    "        for inds in corrs[sz][i]:\n",
    "            corrs_rho[rho][i][inds] = density_threshold(corrs[sz][i][inds].values, rho);\n",
    "              \n",
    "            \n",
    "\n",
    "sz = 4;\n",
    "dist_maths_rho = {}\n",
    "bin_corrs_rho = {}\n",
    "for rho in rhos:\n",
    "    bin_corrs_rho[rho] = {}\n",
    "    for i, group in groups:\n",
    "        bin_corrs_rho[rho][i] = {}\n",
    "        for inds in corrs[sz][i]:\n",
    "            bin_corrs_rho[rho][i][inds] = density_threshold(corrs[sz][i][inds].values, rho, binarized=True);\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity for different densities (thresholded weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_maths_rho = {}\n",
    "for i, group in groups:\n",
    "    dist_maths_rho[i] = np.zeros((len(rhos), len(rhos)));\n",
    "    for j, rho in enumerate(rhos):\n",
    "        ind = np.triu_indices(70,1)\n",
    "        for jj, rrho in enumerate(rhos):\n",
    "            x, y = np.mean(extract_tensor_graph(corrs_rho[rho][i]), 0), np.mean(extract_tensor_graph(corrs_rho[rrho][i]), 0)\n",
    "            r, p = pearsonr(x[ind], y[ind]);\n",
    "            dist_maths_rho[i][j,jj] = r;\n",
    "j = 1;\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for i, group in groups:\n",
    "    plt.subplot(1,4,j)\n",
    "    plt.imshow(dist_maths_rho[i])\n",
    "    plt.colorbar()\n",
    "    j+=1;\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity for different densities (thresholded binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_maths_rho = {}\n",
    "for i, group in groups:\n",
    "    dist_maths_rho[i] = np.zeros((len(rhos), len(rhos)));\n",
    "    for j, rho in enumerate(rhos):\n",
    "        ind = np.triu_indices(70,1)\n",
    "        for jj, rrho in enumerate(rhos):\n",
    "            x, y = np.mean(extract_tensor_graph(bin_corrs_rho[rho][i]), 0), np.mean(extract_tensor_graph(bin_corrs_rho[rrho][i]), 0)\n",
    "            r, p = pearsonr(x[ind], y[ind]);\n",
    "            dist_maths_rho[i][j,jj] = r;\n",
    "j = 1;\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "for i, group in groups:\n",
    "    plt.subplot(1,4,j)\n",
    "    plt.imshow(dist_maths_rho[i])\n",
    "    plt.colorbar()\n",
    "    j+=1;\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total heterogeneity of thresholded  networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_het = {}\n",
    "tot_cv = {}\n",
    "\n",
    "for rho in tqdm(rhos):\n",
    "    for i in corrs_rho[rho]:\n",
    "        het = []\n",
    "        cv = []\n",
    "        for inds in corrs_rho[rho][i]:\n",
    "            tg_local = extract_tensor_graph(corrs_rho[rho][i]);\n",
    "            het.append(np.std(tg_local, 0))\n",
    "            cv.append(np.std(tg_local, 0) / np.mean(tg_local, 0));\n",
    "    tot_het[rho] = het\n",
    "    tot_cv[rho] = cv\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_het[x]) for x in rhos], [np.nanstd(tot_het[x]) for x in rhos])\n",
    "plt.subplot(122)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_cv[x]) for x in rhos], [np.nanstd(tot_cv[x]) for x in rhos])\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rhos[np.argmax([np.nanmean(tot_cv[x]) for x in rhos])])\n",
    "rhos[np.argmin([np.nanmean(tot_cv[x]) for x in rhos])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total heterogeneity of thresholded binarized networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_het = {}\n",
    "tot_cv = {}\n",
    "\n",
    "for rho in tqdm(rhos):\n",
    "    for i in bin_corrs_rho[rho]:\n",
    "        het = []\n",
    "        cv = []\n",
    "        for inds in bin_corrs_rho[rho][i]:\n",
    "            tg_local = extract_tensor_graph(bin_corrs_rho[rho][i]);\n",
    "            het.append(np.std(tg_local, 0))\n",
    "            cv.append(np.std(tg_local, 0) / np.mean(tg_local, 0));\n",
    "    tot_het[rho] = het\n",
    "    tot_cv[rho] = cv\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_het[x]) for x in rhos], [np.nanstd(tot_het[x]) for x in rhos])\n",
    "plt.subplot(122)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_cv[x]) for x in rhos], [np.nanstd(tot_cv[x]) for x in rhos])\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos[np.argmax([np.nanmean(tot_cv[x]) for x in rhos])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison with Fallani-Latora method\n",
    "https://github.com/devuci/3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def objective_J(G,rho=None):\n",
    "    if rho==None:\n",
    "        rho = nx.density(G);\n",
    "    return (nx.local_efficiency(G) + nx.global_efficiency(G))/rho;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 8\n",
    "# rhos = np.linspace(0.01,0.2,20)\n",
    "Js = {}\n",
    "for i, group in tqdm(groups):\n",
    "    Js[i] = []\n",
    "    for rho in rhos:\n",
    "        adj = list(corrs[sz][i].values())[0].values\n",
    "        adj = density_threshold(adj, rho, binarized=True)\n",
    "        G = nx.from_numpy_array(adj)\n",
    "        Js[i].append(objective_J(G, rho));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Js:\n",
    "    plt.plot(rhos,Js[i], label=str(i))\n",
    "    print(i, rhos[np.argmax(Js[i])])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = {}\n",
    "sz = 8\n",
    "for i in corrs[sz]:\n",
    "    tg[i] = np.mean(extract_tensor_graph(corrs[sz][i]), 0)\n",
    "    nums = np.reshape(tg[i], (1, 70*70))\n",
    "    print(i, np.quantile(nums,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_J, std_J = [], []\n",
    "for i, rho in enumerate(rhos):\n",
    "    av_J.append(np.nanmean([Js[x][i] for x in Js]))\n",
    "    std_J.append(np.std([Js[x][i] for x in Js]))\n",
    "\n",
    "\n",
    "plt.errorbar(rhos,av_J, std_J)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 2\n",
    "\n",
    "mean_tot_cv = np.array([np.nanmean(tot_cv[x]) for x in rhos])\n",
    "plt.plot(rhos[skip:], mean_tot_cv[skip:]/np.max(mean_tot_cv[skip:]), 'o--')\n",
    "for i in Js:\n",
    "    plt.plot(rhos[skip:],Js[i][skip:]/np.max(Js[i][skip:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_het[x]) for x in rhos], [np.nanstd(tot_het[x]) for x in rhos])\n",
    "plt.plot(rhos, [np.nanmean(tot_het[x]) for x in rhos], 'bo', alpha=.4)\n",
    "plt.ylabel(r'$\\zeta(\\Omega^\\rho)$', fontsize=20)\n",
    "plt.xlabel(r'$\\rho$', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.errorbar(rhos, [np.nanmean(tot_cv[x]) for x in rhos], [np.nanstd(tot_cv[x]) for x in rhos])\n",
    "plt.plot(rhos, [np.nanmean(tot_cv[x]) for x in rhos], 'bo', alpha=.4)\n",
    "plt.ylabel(r'$\\xi(\\Omega^\\rho)$', fontsize=20)\n",
    "plt.ylim(0,10)\n",
    "plt.xlabel(r'$\\rho$', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.errorbar(rhos,av_J, std_J)\n",
    "plt.plot(rhos, av_J, 'bo', alpha=.4)\n",
    "plt.ylabel(r'$J(\\rho)$', afontsize=20)\n",
    "plt.xlabel(r'$\\rho$', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenv",
   "language": "python",
   "name": "stenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
