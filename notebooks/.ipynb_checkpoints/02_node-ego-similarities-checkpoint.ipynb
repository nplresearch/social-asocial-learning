{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of correlation networks using all correlations removing the mean-corr matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:13:35.674107Z",
     "start_time": "2021-12-07T10:13:33.638858Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:13:35.993488Z",
     "start_time": "2021-12-07T10:13:35.676097Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "corrs = pd.read_pickle(open('../data/resampled_corrs.pck', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:13:35.997527Z",
     "start_time": "2021-12-07T10:13:35.995336Z"
    }
   },
   "outputs": [],
   "source": [
    "regions = corrs[4][('P', 'A')][(0, 1, 2, 3)].columns\n",
    "num_regions = len(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_regions = list(regions)\n",
    "substitutes = {'ATN I_l': 'ATN_l', 'ATN I_r': 'ATN_r', 'VL I_l': 'VL_l', 'VL I_r': 'VL_r'}\n",
    "\n",
    "for r in substitutes:\n",
    "    ind = good_regions.index(r);\n",
    "    good_regions[ind] = substitutes[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = good_regions;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:13:36.003314Z",
     "start_time": "2021-12-07T10:13:35.999363Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tensor_graph(graph_tower):\n",
    "    # reshaping\n",
    "    L = len(graph_tower)\n",
    "    x = graph_tower[list(graph_tower.keys())[0]].shape[0]\n",
    "    keys = list(graph_tower.keys())\n",
    "    mat = np.zeros((L, x, x))\n",
    "    for l in range(L):\n",
    "        mat[l, :, :] = graph_tower[keys[l]]\n",
    "    return mat\n",
    "\n",
    "\n",
    "def density_threshold(mat, density, binarized=False):\n",
    "    ind = np.triu_indices_from(mat)\n",
    "    values = mat[ind]\n",
    "    thr_value = np.quantile(values, 1.0-density)\n",
    "    thr_mat = mat.copy()\n",
    "    thr_mat[mat < thr_value] = 0\n",
    "    if binarized == True:\n",
    "        thr_mat[mat >= thr_value] = 1  # binarization\n",
    "    return thr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:13:36.226650Z",
     "start_time": "2021-12-07T10:13:36.004927Z"
    }
   },
   "outputs": [],
   "source": [
    "chosen_rho = 0.07;\n",
    "\n",
    "\n",
    "sz = 4\n",
    "groups = list(corrs[sz].keys())\n",
    "corrs_rho = {}\n",
    "\n",
    "for i in tqdm(groups):\n",
    "    corrs_rho[i] = {}\n",
    "    for inds in corrs[sz][i]:\n",
    "        corrs_rho[i][inds] = density_threshold(\n",
    "            corrs[sz][i][inds].values, chosen_rho)\n",
    "\n",
    "bin_corrs_rho = {}\n",
    "\n",
    "for i in tqdm(groups):\n",
    "    bin_corrs_rho[i] = {}\n",
    "    for inds in corrs[sz][i]:\n",
    "        bin_corrs_rho[i][inds] = density_threshold(\n",
    "            corrs[sz][i][inds].values, chosen_rho, binarized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:26.632173Z",
     "start_time": "2021-12-07T10:14:26.543646Z"
    }
   },
   "outputs": [],
   "source": [
    "av_corrs_rho = {}\n",
    "for i in tqdm(groups):\n",
    "    av_corrs_rho[i] = pd.DataFrame(np.mean(extract_tensor_graph(\n",
    "        corrs_rho[i]), 0), columns=regions, index=regions)\n",
    "\n",
    "av_binarized_corrs_rho = {}\n",
    "for i in tqdm(groups):\n",
    "    av_binarized_corrs_rho[i] = pd.DataFrame(np.mean(\n",
    "        extract_tensor_graph(bin_corrs_rho[i]), 0), columns=regions, index=regions)\n",
    "\n",
    "av_corrs_full = {}\n",
    "for i in tqdm(groups):\n",
    "    av_corrs_full[i] = pd.DataFrame(np.mean(extract_tensor_graph(\n",
    "        corrs[sz][i]), 0), columns=regions, index=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:26.924951Z",
     "start_time": "2021-12-07T10:14:26.919797Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving the average matrices for various densities\n",
    "\n",
    "pk.dump(av_corrs_rho, open('../data/av_corrs_rho_by_group_density'+str(chosen_rho).replace('.','_')+'.pck', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:16:52.732568Z",
     "start_time": "2021-12-07T10:16:52.727653Z"
    }
   },
   "outputs": [],
   "source": [
    "ordered_keys = list(av_corrs_rho.keys())\n",
    "ordered_keys = list(np.array(ordered_keys)[[2,3,0,1]])\n",
    "ordered_keys = list(map(tuple, ordered_keys))\n",
    "ordered_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:58:45.035028Z",
     "start_time": "2021-12-07T10:58:34.642563Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(28,29))\n",
    "for i, n in enumerate(ordered_keys):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    df_corr = av_corrs_rho[n] - np.eye(av_corrs_rho[n].shape[0]);\n",
    "    mask = np.logical_or(np.triu(np.ones_like(df_corr, dtype=np.bool), k=0), np.abs(df_corr.values)<0.1)\n",
    "#     cmap = sns.diverging_palette(0, 230, 90, 60, center='light', as_cmap=True)\n",
    "    sns.heatmap(df_corr, mask=mask, square=True, linewidths=2, cmap='coolwarm',#cmap = cmap,\n",
    "               vmin=0.0, vmax = .3, cbar=False)\n",
    "    plt.title(''.join(n), fontsize=30)\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.savefig('../data/viz-data/julia-adjacency_matrices_high_sig_spearman.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:59:56.201007Z",
     "start_time": "2021-12-07T10:59:56.034719Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 1))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "cmap = mpl.cm.coolwarm\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=.4)\n",
    "\n",
    "# ColorbarBase derives from ScalarMappable and puts a colorbar\n",
    "# in a specified axes, so it has everything needed for a\n",
    "# standalone colorbar.  There are many more kwargs, but the\n",
    "# following gives a basic continuous colorbar with ticks\n",
    "# and labels.\n",
    "cb1 = mpl.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                norm=norm,\n",
    "                                orientation='horizontal')\n",
    "# plt.savefig('../data/viz-data/colorbar.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:22:33.665630Z",
     "start_time": "2021-12-07T10:22:33.479481Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.ravel(df_corr.values), np.linspace(-1,1,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node egonetwork similarities\n",
    "In the following we compute the similarity of node neighbourhoods betweenn conditions. We do this by computing the \n",
    "cosine similarity \n",
    "\\begin{align}\n",
    "s_i^{x,y} = cos(\\theta) = \\frac{\\sum_j a^x_{ij} a^y_{i,j}}{\\sqrt{\\sum_j (a^x_{ij})^2} \\sqrt{\\sum_j (a^y_{i,j})^2}}\n",
    "\\end{align}\n",
    "\n",
    "for node $i$ between condition/pairing $x$ and $y$, where $a^x_{ij}$ is the correlation matrix of condition/pairing $x$.   \n",
    "The idea here is that if $s_i^{x,y}$ is large for $(x,y)$ then in the these two conditions node $i$ hsa the same behaviour and hence plays the same role. In other terms, since it does not change its behaviour between conditions then it can be considered not to be relevant for the transition.  \n",
    "Conversely when $s_i^{x,y}$ is small, node $i$ is changing its behaviour to a large degree between the two conditions and should therefore be considered important in that transition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:27.844940Z",
     "start_time": "2021-12-07T10:14:27.842252Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "conditions = ['P', 'U']\n",
    "social = ['A', 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:28.242404Z",
     "start_time": "2021-12-07T10:14:28.236747Z"
    }
   },
   "outputs": [],
   "source": [
    "def egosine_sim(g, gg):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    es = pd.Series(index=g.columns)\n",
    "    for c in g.columns:\n",
    "        x, y = np.array(g[c]), np.array(gg[c])\n",
    "        es[c] = cosine_similarity(x.reshape(1, len(x)), y.reshape(1, len(y)))\n",
    "    return es\n",
    "\n",
    "\n",
    "def egosine_sim_randomized(g, gg):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    es = pd.Series(index=g.columns)\n",
    "    for c in g.columns:\n",
    "        x, y = np.array(g[c]), np.array(gg[c])\n",
    "        shuffle(x)\n",
    "        shuffle(y)\n",
    "        es[c] = cosine_similarity(x.reshape(1, len(x)), y.reshape(1, len(y)))\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:29.363792Z",
     "start_time": "2021-12-07T10:14:28.813661Z"
    }
   },
   "outputs": [],
   "source": [
    "ego_sim_df = {}\n",
    "for g, gg in combinations(av_corrs_rho.items(), 2):\n",
    "    ego_sim_df[(g[0], gg[0])] = egosine_sim(g[1], gg[1])\n",
    "\n",
    "ego_sim_df = pd.DataFrame(ego_sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:29.532127Z",
     "start_time": "2021-12-07T10:14:29.414401Z"
    }
   },
   "outputs": [],
   "source": [
    "ego_sim_df_random = {}\n",
    "for g, gg in combinations(av_corrs_rho.items(), 2):\n",
    "    ego_sim_df_random[(g[0], gg[0])] = egosine_sim_randomized(g[1], gg[1])\n",
    "\n",
    "ego_sim_df_random = pd.DataFrame(ego_sim_df_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:30.243907Z",
     "start_time": "2021-12-07T10:14:30.240984Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_select(d, k):\n",
    "    if k > 0:\n",
    "        return d[:k]\n",
    "    if k < 0:\n",
    "        return d[k:]\n",
    "\n",
    "\n",
    "topk = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to isolate control effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:31.925412Z",
     "start_time": "2021-12-07T10:14:31.886586Z"
    }
   },
   "outputs": [],
   "source": [
    "print(av_corrs_rho.keys())\n",
    "\n",
    "deltaS = av_corrs_rho[('P', 'S')] - av_corrs_rho[('U', 'S')]\n",
    "deltaA = av_corrs_rho[('P', 'A')] - av_corrs_rho[('U', 'A')]\n",
    "\n",
    "ego_sim_df[('DeltaS', 'DeltaA')] = egosine_sim(deltaS, deltaA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T10:14:32.737626Z",
     "start_time": "2021-12-07T10:14:32.702035Z"
    }
   },
   "outputs": [],
   "source": [
    "deltaP = av_corrs_rho[('P', 'S')] - av_corrs_rho[('P', 'A')]  # social learning\n",
    "deltaU = av_corrs_rho[('U', 'S')] - av_corrs_rho[('U', 'A')]  # pure sociality\n",
    "\n",
    "ego_sim_df[('DeltaP', 'DeltaU')] = egosine_sim(deltaP, deltaU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects on regional similarity of the Social and Asocial treatments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T11:39:56.958930Z",
     "start_time": "2021-12-07T11:39:56.412217Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.linspace(0, 1.5, 10), np.linspace(0, 1.5, 10), 'k--', alpha=.4)\n",
    "plt.scatter(deltaS.apply(np.linalg.norm), deltaA.apply(\n",
    "    np.linalg.norm), c=ego_sim_df[('DeltaS', 'DeltaA')])\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$|\\Delta_i^S|$', fontsize=30)\n",
    "plt.ylabel(r'$|\\Delta_i^A|$', fontsize=30)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.ylim(-.6, .6)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../data/viz-data/deltaA_deltaS_scatterplot.pdf')\n",
    "\n",
    "pearsonr(deltaS.apply(np.linalg.norm), deltaA.apply(np.linalg.norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construction of expected values for norms of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:08:42.819995Z",
     "start_time": "2021-09-02T10:08:42.337713Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of expected values for norms of columns, tot be used below to identify large/small changes\n",
    "norms_S = []\n",
    "vals = deltaS.values.reshape(num_regions*num_regions)\n",
    "n_samples = 10000\n",
    "for n in range(n_samples):\n",
    "    norms_S.append(np.linalg.norm(choice(vals, num_regions)))\n",
    "\n",
    "norms_A = []\n",
    "vals = deltaA.values.reshape(num_regions*num_regions)\n",
    "n_samples = 10000\n",
    "for n in range(n_samples):\n",
    "    norms_A.append(np.linalg.norm(choice(vals, num_regions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:08:51.202946Z",
     "start_time": "2021-09-02T10:08:45.704373Z"
    }
   },
   "outputs": [],
   "source": [
    "import bootstrapped.stats_functions as bs_stats\n",
    "import bootstrapped.bootstrap as bs\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "plt.subplot(211)\n",
    "alpha = 0.05\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_S, 1-alpha), np.quantile(norms_S, alpha), alpha=.3)\n",
    "plt.plot(deltaS.apply(np.linalg.norm), 'o')\n",
    "plt.xticks([])\n",
    "deh = bs.bootstrap(np.array(norms_S), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^S_i|$', fontsize=30)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlim(-.2, num_regions-.5)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_A, 1-alpha), np.quantile(norms_S, alpha), alpha=.3)\n",
    "plt.plot(deltaA.apply(np.linalg.norm), 'o')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "deh = bs.bootstrap(np.array(norms_A), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^A_i|$', fontsize=30)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlim(-.2, num_regions-.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/deltaA_deltaS_significances_edit_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bootstrapped.stats_functions as bs_stats\n",
    "import bootstrapped.bootstrap as bs\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "plt.subplot(211)\n",
    "alpha = 0.05\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_S, 1-alpha), np.quantile(norms_S, alpha), alpha=.3)\n",
    "plt.plot(deltaS.apply(np.linalg.norm), 'o')\n",
    "plt.xticks([])\n",
    "deh = bs.bootstrap(np.array(norms_S), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^S_i|$', fontsize=30)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlim(-.2, num_regions-.5)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_A, 1-alpha), np.quantile(norms_S, alpha), alpha=.3)\n",
    "plt.plot(deltaA.apply(np.linalg.norm), 'o')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "deh = bs.bootstrap(np.array(norms_A), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^A_i|$', fontsize=30)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlim(-.2, num_regions-.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/deltaA_deltaS_significances_edit_no_lab.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:17:04.066937Z",
     "start_time": "2021-09-02T10:17:04.035832Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "\n",
    "list_high_intensity, list_low_intensity = {}, {}\n",
    "list_high_intensity['S'] = []\n",
    "list_high_intensity['A'] = []\n",
    "list_low_intensity['S'] = []\n",
    "list_low_intensity['A'] = []\n",
    "\n",
    "up, lo = np.quantile(norms_S, 1-alpha), np.quantile(norms_S, alpha)\n",
    "d = deltaS.apply(np.linalg.norm)\n",
    "for i in d.index:\n",
    "    if d[i] > up:\n",
    "        list_high_intensity['S'].append(\n",
    "            [i, (100 - percentileofscore(norms_S, d[i]))/100])\n",
    "    elif d[i] < lo:\n",
    "        list_low_intensity['S'].append(\n",
    "            [i, percentileofscore(norms_S, d[i])/100])\n",
    "\n",
    "up, lo = np.quantile(norms_A, 1-alpha), np.quantile(norms_A, alpha)\n",
    "d = deltaA.apply(np.linalg.norm)\n",
    "for i in d.index:\n",
    "    if d[i] > up:\n",
    "        list_high_intensity['A'].append(\n",
    "            [i, (100 - percentileofscore(norms_A, d[i]))/100])\n",
    "    elif d[i] < lo:\n",
    "        list_low_intensity['A'].append(\n",
    "            [i, percentileofscore(norms_A, d[i])/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T10:45:09.485025Z",
     "start_time": "2021-09-06T10:45:09.453695Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list_high_intensity)\n",
    "print(list_low_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T10:45:12.256700Z",
     "start_time": "2021-09-06T10:45:12.245536Z"
    }
   },
   "outputs": [],
   "source": [
    "new_high_intensity = {}\n",
    "for k in list_high_intensity:\n",
    "    new_high_intensity[k] = {}\n",
    "    for reg in list_high_intensity[k]:\n",
    "        new_high_intensity[k][reg[0]] = reg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:31:40.899204Z",
     "start_time": "2021-09-02T10:31:40.863967Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(new_high_intensity).to_excel('../data/p-values-high-amplitude-changes.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:28:07.684591Z",
     "start_time": "2021-09-02T10:28:07.681360Z"
    }
   },
   "outputs": [],
   "source": [
    "new_low_intensity = {}\n",
    "for k in list_low_intensity:\n",
    "    new_low_intensity[k] = {}\n",
    "    for reg in list_low_intensity[k]:\n",
    "        new_low_intensity[k][reg[0]] = reg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T10:48:13.430252Z",
     "start_time": "2021-09-06T10:48:13.388265Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(new_low_intensity).to_excel('../data/p-values-low-amplitude-changes.xls')\n",
    "print(pd.DataFrame(new_low_intensity).fillna('-').to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:40:11.105188Z",
     "start_time": "2021-09-02T10:40:11.094601Z"
    }
   },
   "outputs": [],
   "source": [
    "residuals = deltaS.apply(np.linalg.norm) - deltaA.apply(np.linalg.norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual null model for significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:40:12.406110Z",
     "start_time": "2021-09-02T10:40:11.941719Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of expected values for norms of columns, tot be used below to identify large/small changes\n",
    "residual = []\n",
    "valS = deltaS.values.reshape(num_regions*num_regions)\n",
    "valA = deltaA.values.reshape(num_regions*num_regions)\n",
    "n_samples = 10000\n",
    "null_residual = []\n",
    "for n in range(n_samples):\n",
    "    null_residual.append(np.linalg.norm(\n",
    "        choice(valS, num_regions)) - np.linalg.norm(choice(valA, num_regions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:40:13.294622Z",
     "start_time": "2021-09-02T10:40:12.408785Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "(markers, stemlines, baseline) = plt.stem(residuals.values, use_line_collection=True)\n",
    "plt.setp(stemlines, linestyle=\"-\", color=\"blue\", linewidth=0.5)\n",
    "markers.set_markerfacecolor('none')\n",
    "plt.xticks(range(len(residuals)), residuals.index, rotation=90)\n",
    "plt.ylim(-.8, .8)\n",
    "plt.ylabel(r'$|\\Delta^S_i| - |\\Delta^A_i|$', fontsize=20)\n",
    "alpha = 0.05\n",
    "\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    null_residual, 1-alpha), np.quantile(null_residual, alpha), alpha=.3)\n",
    "\n",
    "plt.savefig('../data/viz-data/residual_deltaA_deltaS_significances.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:40:13.854698Z",
     "start_time": "2021-09-02T10:40:13.844164Z"
    }
   },
   "outputs": [],
   "source": [
    "high_residual, low_residual = [], []\n",
    "\n",
    "up, lo = np.quantile(null_residual, 1-alpha), np.quantile(null_residual, alpha)\n",
    "d = deltaS.apply(np.linalg.norm)\n",
    "for r in residuals.index:\n",
    "    if residuals[r] > up:\n",
    "        high_residual.append(r)\n",
    "    elif residuals[r] < lo:\n",
    "        low_residual.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T10:40:14.552741Z",
     "start_time": "2021-09-02T10:40:14.549283Z"
    }
   },
   "outputs": [],
   "source": [
    "print('High: ', high_residual)\n",
    "print('Low: ', low_residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significances of similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:00:59.382359Z",
     "start_time": "2021-09-02T11:00:58.777052Z"
    }
   },
   "outputs": [],
   "source": [
    "inds = list(ego_sim_df.columns)\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(ego_sim_df[('DeltaS', 'DeltaA')], 'o')\n",
    "plt.title(\"Similarity ('DeltaS','DeltaA')\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.hlines(0, 0, 70, linestyles='dashed', alpha=.4)\n",
    "plt.ylim(-.6, .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:08:14.235285Z",
     "start_time": "2021-09-02T11:06:43.443949Z"
    }
   },
   "outputs": [],
   "source": [
    "# creation of the expectations values for the delta_S/Delta_A similarity\n",
    "ego_sim_expectation = pd.DataFrame()\n",
    "num_iter = 5000\n",
    "for n in tqdm(range(num_iter)):\n",
    "    ego_sim_expectation[n] = egosine_sim_randomized(deltaS, deltaA)\n",
    "ego_sim_expectation = ego_sim_expectation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:11:09.629582Z",
     "start_time": "2021-09-02T11:08:14.237529Z"
    }
   },
   "outputs": [],
   "source": [
    "import bootstrapped.stats_functions as bs_stats\n",
    "import bootstrapped.bootstrap as bs\n",
    "from scipy.stats import ttest_1samp\n",
    "significance_color = []\n",
    "for c in regions:\n",
    "    low, high = np.quantile(ego_sim_expectation[c], 0.05), np.quantile(\n",
    "        ego_sim_expectation[c], 0.95)\n",
    "    if ego_sim_df[('DeltaS', 'DeltaA')][c] <= low or ego_sim_df[('DeltaS', 'DeltaA')][c] >= high:\n",
    "        significance_color.append(1)\n",
    "    else:\n",
    "        significance_color.append(0)\n",
    "\n",
    "t_significance_color = []\n",
    "for c in regions:\n",
    "    t, p = ttest_1samp(\n",
    "        ego_sim_expectation[c], ego_sim_df[('DeltaS', 'DeltaA')][c])\n",
    "    if p < 0.05:\n",
    "        t_significance_color.append(1)\n",
    "    else:\n",
    "        t_significance_color.append(0)\n",
    "\n",
    "\n",
    "z_significance_color = []\n",
    "for c in regions:\n",
    "    mu, std = np.mean(ego_sim_expectation[c]), np.std(ego_sim_expectation[c])\n",
    "    z_significance_color.append(\n",
    "        np.abs((ego_sim_df[('DeltaS', 'DeltaA')][c]-mu)/std))\n",
    "\n",
    "\n",
    "boot_significance_color = []\n",
    "conf_intervs = []\n",
    "std_intervs = []\n",
    "for c in regions:\n",
    "    deh = bs.bootstrap(ego_sim_expectation[c].values, stat_func=bs_stats.mean)\n",
    "    std = np.std(ego_sim_expectation[c])\n",
    "    mu = np.mean(ego_sim_df[('DeltaS', 'DeltaA')][c])\n",
    "    if mu < deh.lower_bound or mu >= deh.upper_bound:\n",
    "        boot_significance_color.append(np.abs((mu-deh.value)/std))\n",
    "    else:\n",
    "        boot_significance_color.append(0)\n",
    "    conf_intervs.append([deh.lower_bound, deh.upper_bound])\n",
    "    deh = bs.bootstrap(ego_sim_expectation[c].values, stat_func=bs_stats.std)\n",
    "    std_intervs.append([deh.lower_bound, deh.upper_bound])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:11:11.431241Z",
     "start_time": "2021-09-02T11:11:09.632850Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 5))\n",
    "plt.scatter(range(70), ego_sim_df[(\n",
    "    'DeltaS', 'DeltaA')], c = boot_significance_color, vmax = 5)\n",
    "plt.title(\"Similarity ('DeltaS','DeltaA')\")\n",
    "plt.boxplot(ego_sim_expectation, positions = list(range(70)), showfliers = False)\n",
    "plt.hlines(0, 0, 70, linestyles = 'dashed', alpha = .4)\n",
    "plt.ylim(-.6, .6)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(70), regions, rotation = 90)\n",
    "plt.xlim(-1, 71)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:11:12.682361Z",
     "start_time": "2021-09-02T11:11:11.433991Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.scatter(range(num_regions), ego_sim_df[('DeltaS', 'DeltaA')], c=z_significance_color,\n",
    "            s=100*np.array(significance_color), vmax=5,  vmin=1, cmap='Greys', alpha=1)\n",
    "plt.ylabel(r\" $\\chi(\\Delta^S_i, \\Delta^A_i)$\", fontsize=25)\n",
    "for n in range(num_regions):\n",
    "    plt.vlines(n, (conf_intervs[n][0]+conf_intervs[n][1])/2 - std_intervs[n][1], (conf_intervs[n][0]+conf_intervs[n][1])/2 + std_intervs[n][1],\n",
    "               'k', linestyles='solid', lw=2)\n",
    "# plt.boxplot(ego_sim_expectation.T, positions=range(70), showfliers=False);\n",
    "plt.hlines(0, 0, 70, linestyles='dashed', alpha=.4)\n",
    "plt.ylim(-.6, .6)\n",
    "plt.colorbar(label=r\"z-score\")\n",
    "plt.xticks(range(num_regions), regions, rotation=90)\n",
    "plt.xlim(-1, num_regions+1)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/similarity_SA_vs_random_expection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T11:11:12.755584Z",
     "start_time": "2021-09-02T11:11:12.684143Z"
    }
   },
   "outputs": [],
   "source": [
    "# list significant regionss and their up/down regulation\n",
    "from scipy.stats import percentileofscore\n",
    "down_regulation, up_regulation = [], []\n",
    "\n",
    "for c in regions:\n",
    "    mu, std = np.mean(ego_sim_expectation[c]), np.std(ego_sim_expectation[c])\n",
    "    low, high = np.quantile(ego_sim_expectation[c], 0.05), np.quantile(\n",
    "        ego_sim_expectation[c], 1-0.05)\n",
    "    if ego_sim_df[('DeltaS', 'DeltaA')][c] <= low:\n",
    "        perc = percentileofscore(\n",
    "            ego_sim_expectation[c], ego_sim_df[('DeltaS', 'DeltaA')][c])/100.0\n",
    "        z = (ego_sim_df[('DeltaS', 'DeltaA')][c] - mu)/std\n",
    "        down_regulation.append((c, perc, z))\n",
    "    if ego_sim_df[('DeltaS', 'DeltaA')][c] >= high:\n",
    "        perc = (\n",
    "            100.0 - percentileofscore(ego_sim_expectation[c], ego_sim_df[('DeltaS', 'DeltaA')][c]))/100.0\n",
    "        z = (ego_sim_df[('DeltaS', 'DeltaA')][c] - mu)/std\n",
    "        up_regulation.append((c, perc, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T12:48:58.629162Z",
     "start_time": "2021-09-02T12:48:58.621152Z"
    }
   },
   "outputs": [],
   "source": [
    "down_r_df = pd.DataFrame(down_regulation, columns=['region', 'p-value', 'z-score']).set_index('region')\n",
    "down_r_df.to_excel('../data/p-values-significant-dissimilarities.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:22:54.037614Z",
     "start_time": "2021-09-06T11:22:54.028085Z"
    }
   },
   "outputs": [],
   "source": [
    "print(down_r_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T12:43:37.742442Z",
     "start_time": "2021-09-02T12:43:37.730481Z"
    }
   },
   "outputs": [],
   "source": [
    "print(up_regulation)\n",
    "np.min([x[2] for x in up_regulation]), np.max([x[1] for x in up_regulation])\n",
    "print([x[0] for x in up_regulation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T12:48:26.568371Z",
     "start_time": "2021-09-02T12:48:26.557284Z"
    }
   },
   "outputs": [],
   "source": [
    "up_r_df = pd.DataFrame(up_regulation, columns=['region', 'p-value', 'z-score']).set_index('region')\n",
    "up_r_df.to_excel('../data/p-values-significant-similarities.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T11:22:23.423067Z",
     "start_time": "2021-09-06T11:22:23.411320Z"
    }
   },
   "outputs": [],
   "source": [
    "print(up_r_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects on regional similarity of the Paired and Unpaired treatments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.765989Z",
     "start_time": "2021-08-30T18:05:17.303Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.linspace(0, 1.5, 10), np.linspace(0, 1.5, 10), 'k--', alpha=.4)\n",
    "plt.scatter(deltaP.apply(np.linalg.norm), deltaU.apply(\n",
    "    np.linalg.norm), c=ego_sim_df[('DeltaP', 'DeltaU')])\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$|\\Delta_i^P|$', fontsize=30)\n",
    "plt.ylabel(r'$|\\Delta_i^U|$', fontsize=30)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.ylim(-.6, .6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/deltaP_deltaU_scatterplot.pdf')\n",
    "pearsonr(deltaP.apply(np.linalg.norm), deltaU.apply(np.linalg.norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.767881Z",
     "start_time": "2021-08-30T18:05:17.769Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of expected values for norms of columns, tot be used below to identify large/small changes\n",
    "norms_P = []\n",
    "vals = deltaP.values.reshape(num_regions*num_regions)\n",
    "n_samples = 10000\n",
    "for n in range(n_samples):\n",
    "    norms_P.append(np.linalg.norm(choice(vals, num_regions)))\n",
    "\n",
    "norms_U = []\n",
    "vals = deltaU.values.reshape(num_regions*num_regions)\n",
    "n_samples = 10000\n",
    "for n in range(n_samples):\n",
    "    norms_U.append(np.linalg.norm(choice(vals, num_regions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.769698Z",
     "start_time": "2021-08-30T18:05:17.990Z"
    }
   },
   "outputs": [],
   "source": [
    "import bootstrapped.stats_functions as bs_stats\n",
    "import bootstrapped.bootstrap as bs\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.subplot(211)\n",
    "alpha = 0.05\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_P, 1-alpha), np.quantile(norms_P, alpha), alpha=.3)\n",
    "plt.plot(deltaP.apply(np.linalg.norm), 'o')\n",
    "plt.xticks([])\n",
    "deh = bs.bootstrap(np.array(norms_P), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^P_i|$', fontsize=30)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.fill_between(range(num_regions), np.quantile(\n",
    "    norms_U, 1-alpha), np.quantile(norms_U, alpha), alpha=.3)\n",
    "plt.plot(deltaU.apply(np.linalg.norm), 'o')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "deh = bs.bootstrap(np.array(norms_U), stat_func=bs_stats.mean)\n",
    "plt.hlines(deh.value, 0, num_regions, 'k', alpha=.4)\n",
    "plt.ylabel(r'$|\\Delta^U_i|$', fontsize=30)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/deltaP_deltaU_significances.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.771353Z",
     "start_time": "2021-08-30T18:05:18.148Z"
    }
   },
   "outputs": [],
   "source": [
    "list_high_intensity['P'] = []\n",
    "list_high_intensity['U'] = []\n",
    "list_low_intensity['P'] = []\n",
    "list_low_intensity['U'] = []\n",
    "\n",
    "up, lo = np.quantile(norms_P, 1-alpha), np.quantile(norms_P, alpha)\n",
    "d = deltaP.apply(np.linalg.norm)\n",
    "for i in d.index:\n",
    "    if d[i] > up:\n",
    "        list_high_intensity['P'].append(i)\n",
    "    elif d[i] < lo:\n",
    "        list_low_intensity['P'].append(i)\n",
    "\n",
    "up, lo = np.quantile(norms_U, 1-alpha), np.quantile(norms_U, alpha)\n",
    "d = deltaU.apply(np.linalg.norm)\n",
    "for i in d.index:\n",
    "    if d[i] > up:\n",
    "        list_high_intensity['U'].append(i)\n",
    "    elif d[i] < lo:\n",
    "        list_low_intensity['U'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.776922Z",
     "start_time": "2021-08-30T18:05:18.335Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list_high_intensity)\n",
    "\n",
    "print(list_low_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.779377Z",
     "start_time": "2021-08-30T18:05:18.511Z"
    }
   },
   "outputs": [],
   "source": [
    "# creation of the expectations values for the delta_S/Delta_A similarity\n",
    "ego_sim_expectation_UP = pd.DataFrame()\n",
    "num_iter = 1000\n",
    "for n in tqdm(range(num_iter)):\n",
    "    ego_sim_expectation_UP[n] = egosine_sim_randomized(deltaU, deltaP)\n",
    "ego_sim_expectation_UP = ego_sim_expectation_UP.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.781068Z",
     "start_time": "2021-08-30T18:05:18.676Z"
    }
   },
   "outputs": [],
   "source": [
    "import bootstrapped.stats_functions as bs_stats\n",
    "import bootstrapped.bootstrap as bs\n",
    "from scipy.stats import ttest_1samp\n",
    "significance_color = []\n",
    "for c in regions:\n",
    "    low, high = np.quantile(ego_sim_expectation_UP[c], 0.05), np.quantile(\n",
    "        ego_sim_expectation_UP[c], 0.95)\n",
    "    if ego_sim_df[('DeltaP', 'DeltaU')][c] <= low or ego_sim_df[('DeltaP', 'DeltaU')][c] >= high:\n",
    "        significance_color.append(1)\n",
    "    else:\n",
    "        significance_color.append(0)\n",
    "\n",
    "\n",
    "z_significance_color = []\n",
    "for c in regions:\n",
    "    mu, std = np.mean(ego_sim_expectation_UP[c]), np.std(\n",
    "        ego_sim_expectation_UP[c])\n",
    "    z_significance_color.append(\n",
    "        np.abs((ego_sim_df[('DeltaP', 'DeltaU')][c]-mu)/std))\n",
    "\n",
    "\n",
    "conf_intervs = []\n",
    "std_intervs = []\n",
    "for c in regions:\n",
    "    deh = bs.bootstrap(\n",
    "        ego_sim_expectation_UP[c].values, stat_func=bs_stats.mean)\n",
    "    conf_intervs.append([deh.lower_bound, deh.upper_bound])\n",
    "    deh = bs.bootstrap(\n",
    "        ego_sim_expectation_UP[c].values, stat_func=bs_stats.std)\n",
    "    std_intervs.append([deh.lower_bound, deh.upper_bound])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.782535Z",
     "start_time": "2021-08-30T18:05:18.863Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.scatter(range(num_regions), ego_sim_df[('DeltaP', 'DeltaU')], c=z_significance_color,\n",
    "            s=100*np.array(significance_color), vmax=5,  vmin=1, cmap='Greys', alpha=1)\n",
    "plt.ylabel(r\" $\\chi(\\Delta^P_i, \\Delta^U_i)$\", fontsize=25)\n",
    "for n in range(num_regions):\n",
    "    plt.vlines(n, (conf_intervs[n][0]+conf_intervs[n][1])/2 - std_intervs[n][1], (conf_intervs[n][0]+conf_intervs[n][1])/2 + std_intervs[n][1],\n",
    "               'k', linestyles='solid', lw=2)\n",
    "# plt.boxplot(ego_sim_expectation.T, positions=range(70), showfliers=False);\n",
    "plt.hlines(0, 0, 70, linestyles='dashed', alpha=.4)\n",
    "plt.ylim(-.6, .6)\n",
    "plt.colorbar(label=r\"z-score\")\n",
    "plt.xticks(range(num_regions), regions, rotation=90)\n",
    "plt.xlim(-1, num_regions+1)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz-data/similarity_UP_vs_random_expection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.783952Z",
     "start_time": "2021-08-30T18:05:19.058Z"
    }
   },
   "outputs": [],
   "source": [
    "# list significant regionss and their up/down regulation\n",
    "from scipy.stats import percentileofscore\n",
    "down_regulation, up_regulation = [], []\n",
    "\n",
    "for c in regions:\n",
    "    mu, std = np.mean(ego_sim_expectation_UP[c]), np.std(\n",
    "        ego_sim_expectation_UP[c])\n",
    "    low, high = np.quantile(ego_sim_expectation_UP[c], 0.05), np.quantile(\n",
    "        ego_sim_expectation_UP[c], 1-0.05)\n",
    "    if ego_sim_df[('DeltaS', 'DeltaA')][c] <= low:\n",
    "        perc = percentileofscore(\n",
    "            ego_sim_expectation_UP[c], ego_sim_df[('DeltaP', 'DeltaU')][c])/100.0\n",
    "        z = (ego_sim_df[('DeltaP', 'DeltaU')][c] - mu)/std\n",
    "        down_regulation.append((c, perc, z))\n",
    "    if ego_sim_df[('DeltaP', 'DeltaU')][c] >= high:\n",
    "        perc = (\n",
    "            100.0 - percentileofscore(ego_sim_expectation_UP[c], ego_sim_df[('DeltaP', 'DeltaU')][c]))/100.0\n",
    "        z = (ego_sim_df[('DeltaP', 'DeltaU')][c] - mu)/std\n",
    "        up_regulation.append((c, perc, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.785455Z",
     "start_time": "2021-08-30T18:05:19.264Z"
    }
   },
   "outputs": [],
   "source": [
    "print(down_regulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.787160Z",
     "start_time": "2021-08-30T18:05:19.473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(up_regulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.788834Z",
     "start_time": "2021-08-30T18:05:19.775Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "eigen = {}\n",
    "topk = 10\n",
    "for i in av_corrs_rho:\n",
    "    g = nx.from_pandas_adjacency(av_corrs_rho[i])\n",
    "    eigen[i] = nx.eigenvector_centrality(g)\n",
    "    sorted_eig = sorted(eigen[i].items(), key=operator.itemgetter(1))\n",
    "    print(i, k_select(sorted_eig, -topk), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.791093Z",
     "start_time": "2021-08-30T18:05:20.276Z"
    }
   },
   "outputs": [],
   "source": [
    "degree = {}\n",
    "topk = 10\n",
    "for i in av_corrs_rho:\n",
    "    g = nx.from_pandas_adjacency(av_corrs_rho[i])\n",
    "    degree[i] = nx.degree_centrality(g)\n",
    "    sorted_deg = sorted(degree[i].items(), key=operator.itemgetter(1))\n",
    "    print(i, k_select(sorted_deg, -topk), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T18:05:40.792616Z",
     "start_time": "2021-08-30T18:05:20.531Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in av_corrs_rho:\n",
    "    g = nx.from_pandas_adjacency(av_corrs_rho[i])\n",
    "    degree[i] = nx.degree_centrality(g)\n",
    "    sorted_deg = sorted(degree[i].items(), key=operator.itemgetter(1))\n",
    "    print(i, k_select(sorted_deg, topk), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stenv",
   "language": "python",
   "name": "stenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
